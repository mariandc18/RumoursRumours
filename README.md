# DetecciÃ³n de rumores en Twitter mediante caracterÃ­sticas sociales y lingÃ¼Ã­sticas

## ğŸ” Sobre el Proyecto

Este proyecto aborda el problema de la **detecciÃ³n de desinformaciÃ³n (rumores)** en redes sociales utilizando el **dataset PHEME**.  
A diferencia de enfoques basados en anÃ¡lisis semÃ¡ntico del texto, este trabajo se centra en **caracterÃ­sticas estructurales y de interacciÃ³n social**, como:

- NÃºmero de retweets  
- NÃºmero de favoritos  
- Tipo de evento  
- DinÃ¡mica de difusiÃ³n del hilo  
- Longitud de texto del tweet

El objetivo principal es evaluar hasta quÃ© punto estas seÃ±ales permiten distinguir entre informaciÃ³n verdadera y falsa **sin analizar directamente el contenido textual**.

---

## ğŸ“‚ Datos

### Dataset

- **Nombre:** PHEME Rumour Dataset  
- **Fuente oficial:**  
  ğŸ‘‰ <https://figshare.com/articles/dataset/PHEME_dataset_of_rumours_and_non-rumours/4010619>  

El dataset no se incluye directamente en el repositorio debido a su tamaÃ±o y licencia.  
El usuario debe descargarlo manualmente desde el enlace oficial y colocarlo en la carpeta correspondiente.

---

## ğŸ—‚ï¸ Estructura del Repositorio

```text
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Dataset original PHEME en csv
â”‚   â””â”€â”€ processed/           # Datos procesados listos para entrenamiento
â”œâ”€â”€ dataset/                 #  Dataset original
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ load_data.ipynb      # AnÃ¡lisis exploratorio y carga inicial
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/             # Figuras y visualizaciones generadas
â”‚   â”œâ”€â”€ metrics/             # MÃ©tricas y resultados de evaluaciÃ³n
â”‚   â”œâ”€â”€ models/              # Modelos entrenados
â”‚   â””â”€â”€ label_mappings.json  # Mapeo de etiquetas
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ crossvalidation.py   # BÃºsqueda de hiperparÃ¡metros (CV)
â”‚   â”œâ”€â”€ eval.py              # EvaluaciÃ³n final del modelo
â”‚   â”œâ”€â”€ models.py            # DefiniciÃ³n de modelos ML
â”‚   â”œâ”€â”€ preprocess.py        # Preprocesamiento para entrenamiento
â”‚   â””â”€â”€ train.py             # Entrenamiento de modelos
â”œâ”€â”€ src/
â”‚   â””â”€â”€ preprocess/
â”‚       â”œâ”€â”€ build_raw.py     # ConsolidaciÃ³n del dataset en CSV
â”‚       â””â”€â”€ build_features.py# GeneraciÃ³n de features finales
â”œâ”€â”€ run_all.py               # EjecuciÃ³n completa del pipeline
â”œâ”€â”€ requirements.txt         # Dependencias del proyecto
â””â”€â”€ README.md

```

---

## âš™ï¸ InstalaciÃ³n

**Prerrequisitos**
- Python â‰¥ 3.9
- `pip` o `conda`

**Crear entorno virtual**

```bash
python -m venv venv
source venv/bin/activate   # Linux / Mac
venv\Scripts\activate      # Windows
```

**Instalar dependencias**

```bash
pip install -r requirements.txt
```

---

## Uso

### PreparaciÃ³n de los datos

Una vez descargado el dataset desde el enlace oficial, colÃ³calo en la raÃ­z del repositorio dentro de una carpera 'dataset'.

Luego ejecuta:

```bash
python src/preprocess/build_raw.py
```

Este script consolida el dataset completo en un Ãºnico archivo CSV.
A continuaciÃ³n, genera las caracterÃ­sticas finales para entrenamiento:

```bash
python src/preprocess/build_features.py
```

El dataset final se guardarÃ¡ en **data/processed/**.

### Ejecutar el pipeline completo de Machine Learning

```bash
python run_all.py
```

Este comando ejecuta, en orden:

- Preprocesamiento
- Entrenamiento de modelos
- OptimizaciÃ³n de hiperparÃ¡metros
- EvaluaciÃ³n final

### Si se desea ejecutar solo una parte del pipeline

#### Entrenamiento de un modelo en especÃ­fico

```bash
python scripts/train.py --model random_forest
```

#### ValidaciÃ³n cruzada

```bash
python scripts/crossvalidation.py --model random_forest
```

#### EvaluaciÃ³n del modelo entrenado

```bash
python scripts/evaluate.py --model random_forest
````

Los resultados se almacenan automÃ¡ticamente en la carpeta **outputs/**.

---

#### Modelos disponibles

- random_forest
- decision_tree
- logistic_regression
- xgboost
